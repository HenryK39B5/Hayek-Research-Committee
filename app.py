# app.py: å“ˆè€¶å…‹ç ”ç©¶å§”å‘˜ä¼š Streamlit ç½‘é¡µåº”ç”¨ï¼ˆä¼˜åŒ–é˜…è¯»å™¨äº¤äº’ï¼‰
import streamlit as st
from query_handler import handle_query
from dotenv import load_dotenv
import os
import re

# åŠ è½½ .env
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(page_title="å“ˆè€¶å…‹ç ”ç©¶å§”å‘˜ä¼š", page_icon="ğŸ“š", layout="wide")

# ä¼šè¯çŠ¶æ€ï¼šä¿å­˜å†å²è®°å½•
if "history" not in st.session_state:
    st.session_state.history = []

# ä¾§è¾¹æ ï¼šè®¾ç½®å’Œå¸®åŠ©
with st.sidebar:
    st.title("è®¾ç½®")
    st.markdown("æ¬¢è¿ï¼è¾“å…¥ä¸­æ–‡é—®é¢˜ï¼Œè·å– Hayek è§‚ç‚¹åˆ†æã€‚")
    if st.button("æ¸…ç©ºå†å²"):
        st.session_state.history = []
        st.rerun()

# ä¸»é¡µé¢
st.title("å“ˆè€¶å…‹ç ”ç©¶å§”å‘˜ä¼š")
st.markdown("è¯·è¾“å…¥æ‚¨çš„ä¸­æ–‡é—®é¢˜ï¼ˆä¾‹å¦‚ï¼š'å“ˆè€¶å…‹å¦‚ä½•çœ‹å¾…ä¸­å¤®è®¡åˆ’ç»æµï¼Ÿ'ï¼‰ï¼Œç„¶åç‚¹å‡»æäº¤ã€‚")

question = st.text_input("æ‚¨çš„æé—®ï¼š", key="input")

if st.button("æäº¤") and question:
    with st.spinner("å§”å‘˜ä¼šæ­£åœ¨åˆ†æä¸­...ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰"):
        try:
            report, retrieved_chunks, keywords = handle_query(question)
            st.session_state.history.append({"question": question, "report": report, "chunks": retrieved_chunks, "keywords": keywords})
        except Exception as e:
            st.error(f"å¤„ç†å‡ºé”™ï¼š{e}ã€‚è¯·æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œæˆ– API key æ˜¯å¦æœ‰æ•ˆã€‚")

# æ˜¾ç¤ºå†å²æŠ¥å‘Šï¼Œå¹¶åœ¨æ¯ä¸ªæŠ¥å‘Šåº•éƒ¨åŠ  chunks é˜…è¯»å™¨ï¼ˆç”¨ tabs ä½œä¸ºæ ‡ç­¾é¡µï¼‰
for entry in st.session_state.history:
    with st.chat_message("user"):
        st.markdown(f"**æé—®ï¼š** {entry['question']}")
    with st.chat_message("assistant"):
        # åœ¨æŠ¥å‘Šä¸­å±•ç¤ºå…³é”®è¯
        if entry.get("keywords"):
            keywords_str = ', '.join(entry["keywords"])
            st.markdown(f"**æå–å…³é”®è¯ï¼š** {keywords_str}")
            st.markdown("---")
        st.markdown(entry['report'])
    
    # åº•éƒ¨ chunks é˜…è¯»å™¨ï¼ˆç”¨ tabs æ ‡ç­¾é¡µï¼Œæ¯ä¸ª tab ä¸€ä¸ª chunkï¼Œé«˜äº®å…³é”®è¯ï¼‰
    chunks = entry.get("chunks", [])
    keywords = entry.get("keywords", [])
    
    if chunks:
        st.markdown("### æ¥æº Chunks é˜…è¯»å™¨")
        st.caption("é€‰æ‹©æ ‡ç­¾é¡µæŸ¥çœ‹ä¸åŒæ–‡æ¡£å†…å®¹ï¼ˆé«˜äº®å…³é”®è¯ï¼‰")
        
        # CSS ç¾åŒ–ï¼šé˜…è¯» paneã€é«˜äº®ï¼ˆè«å…°è¿ªæµ…ç°è“ #B0C4DEï¼‰
        st.markdown("""
            <style>
            .reading-content {
                background-color: white;
                padding: 20px;
                border-radius: 10px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                font-family: 'Georgia', serif;
                line-height: 1.6;
                overflow-y: auto;
                max-height: 400px;
            }
            .highlight {
                background-color: #B0C4DE;  /* è«å…°è¿ªæµ…ç°è“ */
                padding: 2px 4px;
                border-radius: 3px;
                font-weight: bold;
                color: #333;
            }
            </style>
        """, unsafe_allow_html=True)
        
        # ç”¨ tabs ä½œä¸ºæ ‡ç­¾é¡µï¼ˆæ¨ªå‘æ’åˆ—ï¼‰
        tab_titles = [f"æ–‡æ¡£ {i+1}" for i in range(len(chunks))]
        tabs = st.tabs(tab_titles)
        
        for i, tab in enumerate(tabs):
            with tab:
                chunk = chunks[i]
                st.markdown(f"**æ¥æºï¼š** {chunk['metadata']['source_file']} | **IDï¼š** {chunk['metadata']['chunk_id']} | **é¡µç ä¼°ç®—ï¼š** {chunk['metadata']['page_estimate']}")
                
                # é«˜äº®å…³é”®è¯
                chunk_text = chunk['text']
                for kw in keywords:
                    chunk_text = re.sub(rf'\b({re.escape(kw)})\b', r'<span class="highlight">\1</span>', chunk_text, flags=re.I)
                
                st.markdown(f'<div class="reading-content">{chunk_text}</div>', unsafe_allow_html=True)
    else:
        st.info("æ— å¬å› chunksã€‚")
    
    st.markdown("---")  # åˆ†éš”å†å² entry

# åº•éƒ¨æç¤º
st.caption("This is AI-generated inspiration based on Hayek's works, not authoritative interpretation.")